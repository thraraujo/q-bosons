\section{Schur Polynomials}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Complete symmetric functions.} 

Using the definition of the homogeneous complete symmetric
polynomial~(\ref{eq:com-hom-sym-pol}), the Miwa coordinatees \(t_j =
j^{-1}\sum_i x_i^j\), it is easy to show that \(h_i(\vec{x})\) are
given by
\begin{equation}
\sum_{k=0}^\infty h_k(\vec{x}) z^k := \prod_{i=1}^m\frac{1}{1-x_i z}\; ,
\end{equation} 
for \(\vec{x}=(x_1, x_2, \dots, x_m)\). Explicitly, we have~\cite{Prasad2018}
\begin{equation}
\begin{split}
    h_k(\vec{x}) & = \sum_{\vec{j}_k^{\ \leq}} x_{j_1}\cdots x_{j_k}\; , \quad 
    \vec{j}_k^{\ \leq}:=\{ (j_1, \dots, j_k)\ |\ 1 \leq j_1\leq \cdots \leq j_k\leq m \}\; .
\end{split}
\end{equation}
Consider, for simplicity, the case \(m=3\), then
\begin{subequations} 
\begin{equation}
\begin{split} 
    h_1&  = x_1 + x_2 + x_3\\
    h_2&  = x^2_1 + x^2_2 + x^2_3+x_1 x_2 + x_1 x_3 + x_2 x_3\\
    h_3&  = x^3_1 + x^3_2 + x^3_3+x_1^2 x_2 + +x_1^2 x_3 + +x_2^2 x_1 + x_2^2 x_3 
    +x_3^2 x_1 +x_3^2 x_1 + x_1 x_2 x_3\; .
\end{split}			
\end{equation}
\end{subequations} 

These functions satisfy some important
properties~\cite{Foda:2009zz}. For example
\begin{subequations}
\begin{equation}
\label{hiden01}
h_k(\vec{x}) = h_k(\hat{x}_i) + x_{i} h_{k-1}(\vec{x}) \; ,
\end{equation}
where \(\hat{x}_i\) is the set \(\vec{x}\) without the coordinate
\(x_i\). The proof of this identity is straightforward, for example,
we can pick an arbitrary coordinate \(x_i\) and split the functions
\(h_k(\vec{x})\) in two terms, the first term does not have the chosen
coordinate \(x_i\) and it is simply \(h_k(\hat{x}_i)\), whilst the
second term, \(\tilde{h}_k(\vec{x})\) contains all dependence on the
coordinate \(x_m\). That is
\begin{equation}
\begin{split}
h_k(\vec{x}) & = \sum_{1\leq j_1 \leq \cdots \hat{i}\leq j_k\leq m}
x_{j_1}\cdots \hat{x}_i \cdots x_{j_k} + \tilde{h}_k(\vec{x}) \\ & =
h_k(\hat{x}_i) + \tilde{h}_k(\vec{x})
\end{split}
\end{equation}
where \(\hat{x}_i\) denotes omission of this coordinate.  By
construction, the function \(\tilde{h}_k(\vec{x}) \) has at least one
coordinate \(x_i\), then we can collect this term and write it as
\begin{equation}
\tilde{h}_k(\vec{x}) = x_i \sum_{1\leq j_1 \leq \cdots \hat{i}\leq j_{k-1}\leq m} x_{j_1}
\cdots x_{j_{k-1}}= x_m  \tilde{h}_{k-1}(\vec{x})\; .
\end{equation}
Putting all these facts together, we see that the
identity~(\ref{hiden01}) is satisfied.
\end{subequations}

Using~(\ref{hiden01}) we obtain a second useful identity
\begin{equation}
\begin{split}
    h_k(\hat{x}_i) - h_k(\hat{x}_l) & = h_k(\hat{x}_i) - x_i
    h_{k-1}(\vec{x}) -( {h_k(\hat{x}_l) - x_l h_{k-1}(\vec{x}) }
    )\\ & = (x_l- x_i )h_{k-1}(\vec{x})
\end{split}
\end{equation}

\subsection{Schur polynomials}

Starting with the definitions of \cite{Alexandrov:2012tr}, we consider
a generic partition \(\lambda = (\lambda_1, \lambda_2, \dots, \lambda_m)\) and
the infinite vector \(\mathbf{t} = \{ t_1, t_2, t_3, \dots \}\). One
defines the Schur polynomials \(s_\lambda(\mathbf{t})\) as
\begin{equation}
\label{jti01}
s_\lambda(\mathbf{t}) = \det \mathbf{H}\ \qquad \mathbf{H}_{ij} =
h_{\lambda_i -i+j}\; ,\ \ \ i,j=1,\dots, m\; ,
\end{equation}
where \(h_k\) is the \emph{complete symmetric function of degree k} defined by  
\begin{subequations} 
\begin{equation}
\exp\left(  \sum_{k\geq 1} t_k z^k\right): = \sum_{k\geq 0} h_k(\mathbf{t}) z^k \; ,
\end{equation}
with \(h_0=1\) and we also define \(h_{-k}=0\  \forall\ k>0\). Explicitly we have 
\begin{equation}
h_k(\mathbf{t}) = \sum_{k_1+2k_2 +\dots = k}\frac{t_1^{k_1}}{k_1!} \frac{t_2^{k_2}}{k_2!}\cdots
\end{equation}	
Some examples are 
\begin{equation}
\begin{split}
  & h_1(\mathbf{t})=t_1\qquad	h_2(\mathbf{t})=\frac{1}{2}t_1^2 + t_2 \\
  & h_3(\mathbf{t})=\frac{1}{6}t_1^3 + t_1 t_2 + t_3\qquad
  h_4(\mathbf{t})=\frac{1}{24}t_1^4 + \frac{1}{2}t_2^2 
  + \frac{1}{2} t_1^2t_2 +t_1t_3 + t_4 \\
  & h_5=\frac{t_1^5}{120}+\frac{1}{6} t_2 t_1^3+\frac{1}{2} t_3 t_1^2+\frac{1}{2} t_2^2 t_1+t_4 t_1+t_2 t_3+t_5\\
  & h_6= \frac{t_1^6}{720}+\frac{1}{24} t_2 t_1^4+\frac{1}{6} t_3 t_1^3+\frac{1}{4} t_2^2 t_1^2
  +\frac{1}{2} t_4 t_1^2+t_2 t_3 t_1+t_5 t_1+\frac{t_2^3}{6}+\frac{t_3^2}{2}+t_2 t_4+t_6
\end{split}	
\end{equation}
\end{subequations}
For 1-row diagrams with \(n\) boxes \(\lambda = (n)\), we have 
\begin{equation} 
s_{(n)}(\mathbf{t}) = h_n ( \mathbf{t} )\; . 
\end{equation}

In an equivalent manner, one can define the Schur polynomials as 
\begin{equation}
\label{jti02}
s_\lambda(\mathbf{t}) = \det \mathbf{E}\ \qquad \mathbf{E}_{ij} = e_{\lambda_i^t -i+j}\; ,\ \ \  
i,j=1,\dots, \lambda_1\; ,
\end{equation}
where \(\lambda^t\) is the transpose Young diagram, and
\(e_k\) is the \emph{elementary symmetric function of degree k} defined by  
\begin{subequations}
\begin{equation}
\exp\left(  \sum_{k\geq 1} (-1)^{k-1}  t_k z^k\right): = \sum_{k\geq 0} e_k(\mathbf{t}) z^k \; .
\end{equation}
and these functions satisfy
\begin{equation}
e_j(\mathbf{t}) = (-1)^j h_j(-\mathbf{t})	\; .
\end{equation}
For example, the first four terms are
\begin{equation}
\begin{split}
  & e_1(\mathbf{t})=t_1 \qquad	e_2(\mathbf{t})=\frac{1}{2}t_1^2 - t_2 \\
  & e_3(\mathbf{t})=\frac{1}{6}t_1^3 - t_1 t_2 + t_3\qquad
  e_4(\mathbf{t})=\frac{1}{24}t_1^4 + \frac{1}{2}t_2^2 - \frac{1}{2} t_1^2t_2 +t_1t_3 - t_4\\
  & e_5=\frac{t_1^5}{120}-\frac{1}{6} t_2 t_1^3+\frac{1}{2} t_3 t_1^2+\frac{1}{2} t_2^2 t_1-t_4 t_1-t_2 t_3+t_5\\
  & e_6= \frac{t_1^6}{720}-\frac{1}{24} t_2 t_1^4+\frac{1}{6} t_3 t_1^3+\frac{1}{4}
  t_2^2 t_1^2-\frac{1}{2} t_4 t_1^2-t_2 t_3 t_1
  +t_5 t_1+\frac{t_3^2}{2}+t_2 t_4-t_6-\frac{t_2^3}{6}
\end{split}	
\end{equation}
\end{subequations}
For 1-column diagrams with \(n\) boxes, \(\lambda = (1^n)\), we have 
\begin{equation} 
s_{(1^n)}(\mathbf{t}) = e_n ( \mathbf{t} )\; . 
\end{equation}
Equations (\ref{jti01}) and (\ref{jti02}) are known as
\emph{Jacobi-Trudi identities}.

More generally, we have the relation between the 
Young diagram \(\lambda\) and its transpose \(\lambda'\)
\begin{equation}
s_{\lambda}(\mathbf{t})	= (-1)^{|\lambda|} s_{\lambda'}(-\mathbf{t})	\; .
\end{equation}

%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%

\subsection{Skew Schur polynomials:} Consider now two Young diagrams,
\(\lambda = (\lambda_1, \dots, \lambda_m)\) and \(\mu = (\mu_1, \dots,
\mu_n)\), with \(m\geq n\) and \(\mu \subseteq \lambda\) as a Young
diagram, that is \(\{\mu_i \leq \lambda_i \ | \ i = 1\dots, m\}\).
The \emph{Skew Schur polynomials} \(s_{\lambda/\mu}(\mathbf{t}) \) are
defined by the generalized Jacobi-Trudi identity
\begin{equation}
s_{\lambda/\mu}(\mathbf{t}) = \left. \det\left( h_{\lambda_i-\mu_j
  -i+j} \right)\right|_{i,j=1,\dots, m} = \left. \det\left(
e_{\lambda^t_i-\mu^t_j -i+j} \right)\right|_{i,j=1,\dots, \lambda_1} \; .
\end{equation}
We can also write these functions in terms of the ordinary Schur
functions as
\begin{equation}
s_{\lambda/\mu}(\mathbf{t}) = \sum_{\nu} c_{\mu \nu}^\lambda s_{\nu}(\mathbf{t}) \; ,
\end{equation}
where \(c_{\mu \nu}^\lambda\) are known as \emph{Littlewood-Richardson
coefficients} and are determined by
\begin{equation}
s_{\mu}(\mathbf{t}) s_{\nu}(\mathbf{t})= \sum_{\lambda} c_{\mu
  \nu}^\lambda s_{\lambda}(\mathbf{t})\; .
\end{equation}


\subsection{Special cases} Let us consider some special cases:

\subsubsection{Case 1:} Let us first specialize to \(t_k=z^k/k\). It is easy to see that
\begin{equation}
\label{symm}
\begin{split}
  & h_1=z \quad h_2 = z^2 \quad  h_3 = z^3 \quad h_4 = z^4 \quad 
  h_5 = z^5 \quad h_6 = z^6\quad \dots\quad  h_p = z^p  \dots \\ 
  & e_1=z \quad e_2 = 0 \quad e_3 = 0 \quad e_4 = 0 \quad
  e_5 = 0 \quad e_6 = 0 \quad \dots \quad e_p = 0 \dots
\end{split}
\end{equation}
One can easily see that this result is consistent using the coordinate \(\vec{x}\). 
\begin{equation}
\label{sympol}
t_k = \frac{1}{k}\sum_{i=1}^m x_i^k \; , \quad \vec{x}=(x_1, \dots, x_m)\; ,
\end{equation}
We have just seen that the Schur polynomials form a basis for the space of
symmetric functions. In these variables, we have~\cite{Prasad2018}
\begin{equation}
\begin{split}
    h_k(\vec{x}) & = \sum_{\vec{j}_k^{\ \leq}} x_{j_1}\cdots x_{j_m}\; , \quad 
    \vec{j}_i^{\ \leq}:=\{ (j_1, \dots, j_k)\ |\ 1 \leq j_1\leq \cdots \leq j_k\leq m \}\\
    e_k(\vec{x}) & = \sum_{\vec{j}_k^{\ <}} x_{j_1}\cdots x_{j_m}\; , \quad 
    \vec{j}_i^{\ <}:=\{ (j_1, \dots, j_k)\ |\ 1 \leq j_1< \cdots < j_k\leq m \}
\end{split}
\end{equation}
Consider, for simplicity, the case \(m=3\), then
\begin{subequations} 
\begin{equation}
\begin{split} 
  h_1&  = x_1 + x_2 + x_3\\
  h_2&  = x^2_1 + x^2_2 + x^2_3+x_1 x_2 + x_1 x_3 + x_2 x_3\\
  h_3&  = x^3_1 + x^3_2 + x^3_3+x_1^2 x_2 + +x_1^2 x_3 + +x_2^2 x_1 + x_2^2 x_3 
  +x_3^2 x_1 +x_3^2 x_1 + x_1 x_2 x_3
\end{split}			
\end{equation}
and 
\begin{equation}
\begin{split} 
  e_1&  = x_1 + x_2 + x_3\\
  e_2&  = x_1 x_2 + x_1 x_3 + x_2 x_3\\
  e_3&  = x_1 x_2 x_3
\end{split}			
\end{equation}		
\end{subequations}
Assuming the expansion (\ref{sympol}), the values \(t_k=z^k/k\)
correspond to \(\vec{x} =(z, 0, \dots, 0)\). In this case, it is easy
to see that the symmetric polynomials reduce to (\ref{symm}).

Therefore, if \(t_k = z^k/k\), we have \(h_k=z^k\ \forall \ k\in
\mathbb{N}\) and \(e_l=0\ \forall \ l\geq 2 \). Consequently,
the nontrivial Schur polynomials are row diagrams,
and they are given by
\begin{equation}
  s_{(n)}  (\{z^k / k\}) = z^n\; . 
\end{equation}
Any other diagram vanishes.

We can use the Skew Schur polynomials. We say that two Young diagrams are
interlaced \(\mu \prec \lambda\) if \(\{ \lambda_i \geq \mu_i \geq \lambda_{i+1}
\ | \ i = 1, \dots, m-1\}\). Therefore, one can see that~\cite{Okounkov2001}
\begin{equation}
  \label{eq:schur:case1}
s_{\lambda/\mu}(\{z^k / k\}) =
\left\{ 
\begin{array}{ll}
z^{|\lambda| - |\mu|} & \lambda \succ \mu \\
0 & \lambda \nsucc \mu \\
\end{array}
\right.
\end{equation}
Here is a list of a few Skew Schur polynomials at the values \(t_k = z^k /k\): 
\[
\begin{array}{lllll}
  \hline
    s_{(1)/\emptyset} = z   & s_{(1)/(1)} = 1 &&&	\\
    s_{(2)/\emptyset} = z^2 & s_{(2)/(1)} = z & s_{(2)/(2)} = 1 &\\  
    s_{(2,1)/\emptyset} = 0 & s_{(2,1)/(1)} = z^2 & s_{(2,1)/(1,1)}=z  & s_{(2,1)/(2)}=z & s_{(2,1)/(2,1)}=1  \\ 
    s_{(3,2,1)/\emptyset} = 0 & s_{(3,2,1)/(2,1,0)} = z^3 & s_{(3,2,1)/(3,2,0)}=z & s_{(3,2,1)/(2,2,1)}= z &
    s_{(3,2,1)/(1,0,0)}=0 \\ 
  \hline
\end{array}
\]


\subsubsection{Case 2:} We now consider the case
\(\mathbf{t}_0=(t, 0, \dots)\). In this case we have
\begin{equation}
h_1=e_1=t\; , \ \ h_2=e_2= \frac{1}{2} t^2 \; , \ h_3=e_3 =
\frac{1}{3!} t^3 \; , \ \ h_4 =e_4 = \frac{1}{4!} t^4 \; \ \dots
\ \ h_p = e_p = \frac{1}{p!} t^p \; \dots
\end{equation}
where \(t\) is an arbitrary parameter, but next section we set
\(t=\sqrt{q}\). In this particular case, some Skew Schur polynomials are
\footnote{These results do not seem to agree with the results in
section 2.2 of~\cite{okounkov2003symmetric} and  
equations (2.13) and (2.14) of~\cite{Maeda:2004is}}
\[
\begin{array}{lllll}
  \hline
    s_{(1)/\emptyset} = z   & s_{(1)/(1)} = 1 &&&	\\
    s_{(2)/\emptyset} = z^2/2 & s_{(2)/(1)} = z & s_{(2)/(2)} = 1 &\\  
    {\color{red} s_{(2,1)/\emptyset} = z^3/3} &
      s_{(2,1)/(1)} = z^2 & s_{(2,1)/(1,1)}=z  & s_{(2,1)/(2)}=z & s_{(2,1)/(2,1)}=1  \\ 
    {\color{red} s_{(3,2,1)/\emptyset} = z^6/45} & s_{(3,2,1)/(2,1,0)} = z^3
      & s_{(3,2,1)/(3,2,0)}=z & s_{(3,2,1)/(2,2,1)}= z &
    {\color{red} s_{(3,2,1)/(1,0,0)}= 2 z^5 / 15} \\ 
  \hline
\end{array}
\]
Where we highlight some differences with the previous case. 

% \begin{equation}
% \begin{array}{llllll}
%   \hline
%     s_{(1)} = t     &&&&&	\\ 
%     s_{(2)} = \frac{t^2}{2} & s_{(1,1)}=\frac{t^2}{2}  &&&& \\ 
%     s_{(3)} = \frac{t^3}{6} &
%     s_{(2,1)} = \frac{t^3}{3} & s_{(1,1,1)}=\frac{t^3}{6} &&& \\  
%     s_{(4)} = \frac{t^4}{24} &
%     s_{(3,1)} = \frac{t^4}{8} & s_{(2,1,1)}=\frac{t^4}{8} & s_{(2,2)}=\frac{t^4}{12} &
%     s_{(1^4)}=\frac{t^4}{24} & \\  
%     s_{(5)} = \frac{t^5}{120} &	s_{(4,1)} = \frac{t^5}{30} & s_{(3,2)}=\frac{t^5}{24} &
%     s_{(311)}=\frac{t^5}{20} & s_{(2,2,1)}=\frac{t^5}{24} 
%     & s_{(2,1,1,1)}=\frac{t^5}{30}\\  
%     s_{(1^5)}=\frac{t^5}{120} &&&&& \\ 
%     s_{(6)} = \frac{t^6}{720} & s_{(5,1)} = \frac{t^6}{144} & s_{(4,2)} = \frac{t^6}{80}
%     & s_{(4,1,1)} = \frac{t^6}{72} & s_{(3,3)} = \frac{t^6}{144} & s_{(3,2,1)} = \frac{t^6}{144} \\ 
%     s_{(3,1,1,1)} = \frac{t^6}{72} & s_{(2,2,2)} = \frac{t^6}{72} & s_{(2,2,1,1)} = \frac{t^6}{80}
%     & s_{(2,1,1,1,1)} = \frac{t^6}{144} & s_{(1^6)} = \frac{t^6}{720} &\\ 
%   \hline
% \end{array}
% \end{equation}

One can write these results generically as:
\begin{equation}
\boxed{s_{\lambda/\mu} = C_{\lambda/\mu}\ t^{|\lambda| - |\mu|}}	
\end{equation}
where 
\begin{equation}
C_{\lambda/\mu} = \left.\det h_{\lambda_i - \mu_j -i +j}\right|_{\mathbf{t}=(1, 0, \dots )}\; .
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

